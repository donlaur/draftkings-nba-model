{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from Modeling_Functions.ipynb\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import csv\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing, model_selection, svm, linear_model, metrics\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.cluster import MeanShift\n",
    "import numpy as np\n",
    "from sklearn.exceptions import DataConversionWarning\n",
    "import import_ipynb\n",
    "import Modeling_Functions\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.graphics.api as smg\n",
    "from statsmodels.graphics.plot_grids import scatter_ellipse\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set Prediction Date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "predictions_date = '2018-10-30'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Positional DataFrames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Truncate NBAData After The Prediction Date\n",
    "Remove all rows after the date for which we are predicting. Split size is the proportion of the proportion of the remaining data on which to predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('NBAData.csv')\n",
    "\n",
    "#Sort by date\n",
    "df = df.set_index('GID')\n",
    "df = df.sort_index()\n",
    "df = df.reset_index()\n",
    "\n",
    "#Delete all rows after prediction date\n",
    "df = df[df['Over/Under'] < 1000]\n",
    "date_range = df.index[df['Date']==predictions_date]\n",
    "start_range = date_range[0]\n",
    "end_range = date_range[len(date_range)-1]\n",
    "df = df.truncate(after = end_range)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Drop Unnecessary Columns\n",
    "Drop all columns that are not used to predict scores and save training data in df_orig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df.drop('Year',inplace=True, axis=1)\n",
    "df.drop('Month',inplace=True, axis=1)\n",
    "df.drop('Day',inplace=True, axis=1)\n",
    "df.drop('Team',inplace=True, axis=1)\n",
    "df.drop('Opponent',inplace=True, axis=1)\n",
    "df.drop('Season',inplace=True, axis=1)\n",
    "df.drop('Unnamed: 0',inplace=True, axis=1)\n",
    "df.drop('Away',inplace=True, axis=1)\n",
    "df = df.drop(['Value'],axis=1)\n",
    "#'Avg PTS','Spread','Avg FG','Avg 3P','Avg FT','Avg TRB','Avg TOV','Avg STL','Avg BLK','Avg AST'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Create Dummy Variables\n",
    "Create and columns for a dummy variable for position. Then drop original columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#df_dummy_opp = pd.get_dummies(df['Season+Opp'])\n",
    "df_dummy_pos = pd.get_dummies(df['Position'])\n",
    "df = pd.concat([df, df_dummy_pos], axis=1)\n",
    "df.drop('Season+Opp',inplace=True, axis=1)\n",
    "df.drop('Position',inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Seperate Each Position into Its Own DataFrame for Modeling\n",
    "Seperates each position, pg, sg, sf, pf, c, into its own dataframe and stores those dataframes in df_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ethanariowitsch/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py:3940: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  errors=errors)\n"
     ]
    }
   ],
   "source": [
    "df_pg = df[df['PG'] == 1]\n",
    "df_sg = df[df['SG'] == 1]\n",
    "df_sf = df[df['SF'] == 1]\n",
    "df_pf = df[df['PF'] == 1]\n",
    "df_c = df[df['C'] == 1]\n",
    "\n",
    "df_pg.drop(['SF','SG','PF','C','PG'],inplace=True, axis=1)\n",
    "df_sg.drop(['SF','PG','PF','C','SG'],inplace=True, axis=1)\n",
    "df_sf.drop(['PG','SG','PF','C','SF'],inplace=True, axis=1)\n",
    "df_pf.drop(['SF','SG','PG','C','PF'],inplace=True, axis=1)\n",
    "df_c.drop(['SF','SG','PF','PG','C'],inplace=True, axis=1)\n",
    "\n",
    "df_pg = df_pg.set_index('GID').sort_index().reset_index()\n",
    "df_sg = df_sg.set_index('GID').sort_index().reset_index()\n",
    "df_sf = df_sf.set_index('GID').sort_index().reset_index()\n",
    "df_pf = df_pf.set_index('GID').sort_index().reset_index()\n",
    "df_c = df_c.set_index('GID').sort_index().reset_index()\n",
    "\n",
    "df_pg.drop('GID',inplace=True,axis=1)\n",
    "df_sg.drop('GID',inplace=True,axis=1)\n",
    "df_sf.drop('GID',inplace=True,axis=1)\n",
    "df_pf.drop('GID',inplace=True,axis=1)\n",
    "df_c.drop('GID',inplace=True,axis=1)\n",
    "\n",
    "\n",
    "\n",
    "df_list = [df_pg,df_sg,df_sf,df_pf,df_c]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Save Arrays for Test Data\n",
    "Save Date, Salary, Projected Points, Position, Name columns for the test data that will later be added to predictions.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Find Index at Which to Split DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pg_test_num = Modeling_Functions.get_test_num(df_pg, predictions_date)\n",
    "sg_test_num = Modeling_Functions.get_test_num(df_sg, predictions_date)\n",
    "sf_test_num = Modeling_Functions.get_test_num(df_sf, predictions_date)\n",
    "pf_test_num = Modeling_Functions.get_test_num(df_pf, predictions_date)\n",
    "c_test_num = Modeling_Functions.get_test_num(df_c, predictions_date)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Save Arrays for Later Use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pg_date = np.array(df_pg['Date'])[-pg_test_num:]\n",
    "pg_salary = np.array(df_pg['Salary'])[-pg_test_num:]\n",
    "pg_proj_points = np.array(df_pg['Projected Points'])[-pg_test_num:]\n",
    "pg_names_array = np.array(df_pg['Name'])[-pg_test_num:]\n",
    "df_pg.drop('Date',inplace=True, axis=1)\n",
    "df_pg.drop(['Name'],inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sg_date = np.array(df_sg['Date'])[-sg_test_num:]\n",
    "sg_salary = np.array(df_sg['Salary'])[-sg_test_num:]\n",
    "sg_proj_points = np.array(df_sg['Projected Points'])[-sg_test_num:]\n",
    "sg_names_array = np.array(df_sg['Name'])[-sg_test_num:]\n",
    "df_sg.drop('Date',inplace=True, axis=1)\n",
    "df_sg.drop(['Name'],inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pf_date = np.array(df_pf['Date'])[-pf_test_num:]\n",
    "pf_salary = np.array(df_pf['Salary'])[-pf_test_num:]\n",
    "pf_proj_points = np.array(df_pf['Projected Points'])[-pf_test_num:]\n",
    "pf_names_array = np.array(df_pf['Name'])[-pf_test_num:]\n",
    "df_pf.drop('Date',inplace=True, axis=1)\n",
    "df_pf.drop(['Name'],inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sf_date = np.array(df_sf['Date'])[-sf_test_num:]\n",
    "sf_salary = np.array(df_sf['Salary'])[-sf_test_num:]\n",
    "sf_proj_points = np.array(df_sf['Projected Points'])[-sf_test_num:]\n",
    "sf_names_array = np.array(df_sf['Name'])[-sf_test_num:]\n",
    "df_sf.drop('Date',inplace=True, axis=1)\n",
    "df_sf.drop(['Name'],inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "c_date = np.array(df_c['Date'])[-c_test_num:]\n",
    "c_salary = np.array(df_c['Salary'])[-c_test_num:]\n",
    "c_proj_points = np.array(df_c['Projected Points'])[-c_test_num:]\n",
    "c_names_array = np.array(df_c['Name'])[-c_test_num:]\n",
    "df_c.drop('Date',inplace=True, axis=1)\n",
    "df_c.drop(['Name'],inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Seperate Into Train and Test Sets\n",
    "Creates train and test sets for each position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pg_training_data = np.array(df_pg.drop(['Points'],1))[:-pg_test_num]\n",
    "pg_training_answers = np.array(df_pg['Points'])[:-pg_test_num]\n",
    "pg_test_data = np.array(df_pg.drop(['Points'],1))[-pg_test_num:]\n",
    "pg_test_answers = np.array(df_pg['Points'])[-pg_test_num:]\n",
    "\n",
    "sg_training_data = np.array(df_sg.drop(['Points'],1))[:-sg_test_num]\n",
    "sg_training_answers = np.array(df_sg['Points'])[:-sg_test_num]\n",
    "sg_test_data = np.array(df_sg.drop(['Points'],1))[-sg_test_num:]\n",
    "sg_test_answers = np.array(df_sg['Points'])[-sg_test_num:]\n",
    "\n",
    "sf_training_data = np.array(df_sf.drop(['Points'],1))[:-sf_test_num]\n",
    "sf_training_answers = np.array(df_sf['Points'])[:-sf_test_num]\n",
    "sf_test_data = np.array(df_sf.drop(['Points'],1))[-sf_test_num:]\n",
    "sf_test_answers = np.array(df_sf['Points'])[-sf_test_num:]\n",
    "\n",
    "pf_training_data = np.array(df_pf.drop(['Points'],1))[:-pf_test_num]\n",
    "pf_training_answers = np.array(df_pf['Points'])[:-pf_test_num]\n",
    "pf_test_data = np.array(df_pf.drop(['Points'],1))[-pf_test_num:]\n",
    "pf_test_answers = np.array(df_pf['Points'])[-pf_test_num:]\n",
    "\n",
    "c_training_data = np.array(df_c.drop(['Points'],1))[:-c_test_num]\n",
    "c_training_answers = np.array(df_c['Points'])[:-c_test_num]\n",
    "c_test_data = np.array(df_c.drop(['Points'],1))[-c_test_num:]\n",
    "c_test_answers = np.array(df_c['Points'])[-c_test_num:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression Vs Random Forest Vs Expert Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "pg_lin_pred, pg_for_pred = Modeling_Functions.model_analysis(pg_training_data, pg_training_answers, pg_test_data, pg_test_answers, pg_proj_points, \"PG\")\n",
    "sg_lin_pred, sg_for_pred = Modeling_Functions.model_analysis(sg_training_data, sg_training_answers, sg_test_data, sg_test_answers, sg_proj_points, \"SG\")\n",
    "sf_lin_pred, sf_for_pred = Modeling_Functions.model_analysis(sf_training_data, sf_training_answers, sf_test_data, sf_test_answers, sf_proj_points, \"SF\")\n",
    "pf_lin_pred, pf_for_pred = Modeling_Functions.model_analysis(pf_training_data, pf_training_answers, pf_test_data, pf_test_answers, pf_proj_points, \"PF\")\n",
    "c_lin_pred, c_for_pred = Modeling_Functions.model_analysis(c_training_data, c_training_answers, c_test_data, c_test_answers, c_proj_points, \"C\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine Postion Specific DataFrames\n",
    "Combining the dataframes for each position and calculating the mean absolute error and r2 for both our modeled predictions and expert predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame()\n",
    "\n",
    "results['Name']= np.concatenate([pg_names_array,sg_names_array,sf_names_array,pf_names_array,c_names_array])\n",
    "results['Position']= np.concatenate([np.full(len(pg_lin_pred), \"PG\"), np.full(len(sg_lin_pred), \"SG\"),\n",
    "                                    np.full(len(sf_lin_pred), \"SF\"), np.full(len(pf_lin_pred), \"PF\"),\n",
    "                                    np.full(len(c_lin_pred), \"C\")])\n",
    "results['Salary']= np.concatenate([pg_salary, sg_salary, sf_salary, pf_salary,c_salary])\n",
    "results['Projected Points']= np.concatenate([pg_proj_points, sg_proj_points, sf_proj_points,\n",
    "                                             pf_proj_points, c_proj_points])\n",
    "results['Predicted Points']= np.concatenate([pg_lin_pred, sg_lin_pred, sf_lin_pred,\n",
    "                                             pf_lin_pred, c_lin_pred]).round(1)\n",
    "results['Day']= np.concatenate([pg_date, sg_date, sf_date, pf_date,c_date])\n",
    "results['Points']= np.concatenate([pg_test_answers, sg_test_answers, sf_test_answers,\n",
    "                                             pf_test_answers, c_test_answers])\n",
    "\n",
    "results.to_csv('Predictions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
