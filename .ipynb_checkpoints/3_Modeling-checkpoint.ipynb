{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from ml_functions.ipynb\n",
      "importing Jupyter notebook from ml_functions.ipynb\n",
      "importing Jupyter notebook from ml_functions.ipynb\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import csv\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing, model_selection, svm, linear_model, metrics\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.cluster import MeanShift\n",
    "import numpy as np\n",
    "from sklearn.exceptions import DataConversionWarning\n",
    "import import_ipynb\n",
    "import ml_functions\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.graphics.api as smg\n",
    "from statsmodels.graphics.plot_grids import scatter_ellipse\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Prediction Date and the Proportion of Data to Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_date = '2018-2-11'\n",
    "\n",
    "#split_size=0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Truncate NBAData After The Prediction Date\n",
    "Remove all rows after the date for which we are predicting. Split size is the proportion of the proportion of the remaining data on which to predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('NBAData.csv')\n",
    "\n",
    "#Sort by date\n",
    "df = df.set_index('GID')\n",
    "df = df.sort_index()\n",
    "df = df.reset_index()\n",
    "\n",
    "#Delete all rows after prediction date\n",
    "date_range = df.index[df['Date']==predictions_date]\n",
    "start_range = date_range[0]\n",
    "end_range = date_range[len(date_range)-1]\n",
    "df = df.truncate(after = end_range)\n",
    "df = df[df['Over/Under'] < 1000]\n",
    "\n",
    "#test number is the number of game records we are predicting\n",
    "test_num = len(df.index)-start_range+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop Unnecessary Columns\n",
    "Drop all columns that are not used to predict scores and save training data in df_orig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop('GID',inplace=True,axis=1)\n",
    "df.drop('Year',inplace=True, axis=1)\n",
    "df.drop('Month',inplace=True, axis=1)\n",
    "df.drop('Day',inplace=True, axis=1)\n",
    "df.drop('Team',inplace=True, axis=1)\n",
    "df.drop('Opponent',inplace=True, axis=1)\n",
    "df.drop('Season',inplace=True, axis=1)\n",
    "df.drop('Unnamed: 0',inplace=True, axis=1)\n",
    "df.drop('Away',inplace=True, axis=1)\n",
    "df = df.drop(['Value'],axis=1)\n",
    "#'Avg PTS','Spread','Avg FG','Avg 3P','Avg FT','Avg TRB','Avg TOV','Avg STL','Avg BLK','Avg AST'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Dummy Variables\n",
    "Create and columns for a dummy variable for position. Then drop original columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_dummy_opp = pd.get_dummies(df['Season+Opp'])\n",
    "df_dummy_pos = pd.get_dummies(df['Position'])\n",
    "df = pd.concat([df, df_dummy_pos], axis=1)\n",
    "df.drop('Season+Opp',inplace=True, axis=1)\n",
    "df.drop('Position',inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Set Data Type to Float and Scale DataFrame\n",
    "Setting all values in our dataframe to float64, then scaling the dataframe using an sklearn StandardScaler() to improve program efficiency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#df = df.astype('float64')\n",
    "#names = df.columns\n",
    "#scaler = preprocessing.StandardScaler()\n",
    "#df_scaled = scaler.fit_transform(df)\n",
    "#df_scaled = pd.DataFrame(df_scaled, columns=names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Seperate Each Position into Its Own DataFrame for Modeling\n",
    "Seperates each position, pg, sg, sf, pf, c, into its own dataframe and stores those dataframes in df_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ethanariowitsch/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py:3940: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  errors=errors)\n",
      "/Users/ethanariowitsch/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py:3940: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  errors=errors)\n",
      "/Users/ethanariowitsch/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py:3940: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  errors=errors)\n"
     ]
    }
   ],
   "source": [
    "df_pg = df[df['PG'] == 1]\n",
    "df_sg = df[df['SG'] == 1]\n",
    "df_sf = df[df['SF'] == 1]\n",
    "df_pf = df[df['PF'] == 1]\n",
    "df_c = df[df['C'] == 1]\n",
    "\n",
    "df_pg.drop(['SF','SG','PF','C','PG'],inplace=True, axis=1)\n",
    "df_sg.drop(['SF','PG','PF','C','SG'],inplace=True, axis=1)\n",
    "df_sf.drop(['PG','SG','PF','C','SF'],inplace=True, axis=1)\n",
    "df_pf.drop(['SF','SG','PG','C','PF'],inplace=True, axis=1)\n",
    "df_c.drop(['SF','SG','PF','PG','C'],inplace=True, axis=1)\n",
    "\n",
    "df_list = [df_pg,df_sg,df_sf,df_pf,df_c]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Arrays for Test Data\n",
    "Save Date, Salary, Projected Points, Position, Name columns for the test data that will later be added to predictions.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pg_date = np.array(df_pg['Date'])[-test_num:]\n",
    "pg_salary = np.array(df_pg['Salary'])[-test_num:]\n",
    "pg_proj_points = np.array(df_pg['Projected Points'])[-test_num:]\n",
    "pg_names_array = np.array(df_pg['Name'])[-test_num:]\n",
    "df_pg.drop('Date',inplace=True, axis=1)\n",
    "df_pg.drop(['Name'],inplace=True, axis=1)\n",
    "\n",
    "sg_date = np.array(df_sg['Date'])[-test_num:]\n",
    "sg_salary = np.array(df_sg['Salary'])[-test_num:]\n",
    "sg_proj_points = np.array(df_sg['Projected Points'])[-test_num:]\n",
    "sg_names_array = np.array(df_sg['Name'])[-test_num:]\n",
    "df_sg.drop('Date',inplace=True, axis=1)\n",
    "df_sg.drop(['Name'],inplace=True, axis=1)\n",
    "\n",
    "pf_date = np.array(df_pf['Date'])[-test_num:]\n",
    "pf_salary = np.array(df_pf['Salary'])[-test_num:]\n",
    "pf_proj_points = np.array(df_pf['Projected Points'])[-test_num:]\n",
    "pf_names_array = np.array(df_pf['Name'])[-test_num:]\n",
    "df_pf.drop('Date',inplace=True, axis=1)\n",
    "df_pf.drop(['Name'],inplace=True, axis=1)\n",
    "\n",
    "sf_date = np.array(df_sf['Date'])[-test_num:]\n",
    "sf_salary = np.array(df_sf['Salary'])[-test_num:]\n",
    "sf_proj_points = np.array(df_sf['Projected Points'])[-test_num:]\n",
    "sf_names_array = np.array(df_sf['Name'])[-test_num:]\n",
    "df_sf.drop('Date',inplace=True, axis=1)\n",
    "df_sf.drop(['Name'],inplace=True, axis=1)\n",
    "\n",
    "c_date = np.array(df_c['Date'])[-test_num:]\n",
    "c_salary = np.array(df_c['Salary'])[-test_num:]\n",
    "c_proj_points = np.array(df_c['Projected Points'])[-test_num:]\n",
    "c_names_array = np.array(df_c['Name'])[-test_num:]\n",
    "df_c.drop('Date',inplace=True, axis=1)\n",
    "df_c.drop(['Name'],inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Graphing Variable Correlation to Points for Each Position\n",
    "Graphs Projected Points, Salary, Over/Under, Spread, Avg MP, and Avg DK Points against actual points to get a look at their value as a predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ethanariowitsch/anaconda3/lib/python3.7/site-packages/seaborn/axisgrid.py:2065: UserWarning: The `size` parameter has been renamed to `height`; pleaes update your code.\n",
      "  warnings.warn(msg, UserWarning)\n",
      "/Users/ethanariowitsch/anaconda3/lib/python3.7/site-packages/seaborn/axisgrid.py:2065: UserWarning: The `size` parameter has been renamed to `height`; pleaes update your code.\n",
      "  warnings.warn(msg, UserWarning)\n",
      "/Users/ethanariowitsch/anaconda3/lib/python3.7/site-packages/seaborn/axisgrid.py:2065: UserWarning: The `size` parameter has been renamed to `height`; pleaes update your code.\n",
      "  warnings.warn(msg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "sns.set()\n",
    "i = 0\n",
    "df_names = ['Point Guards', \"Shooting Guards\", \"Small Fowards\", \"Power Fowards\", \"Centers\"]\n",
    "for df in df_list:\n",
    "    g = sns.pairplot(df, kind='reg',x_vars=['Projected Points', \"Salary\", \"Over/Under\", \n",
    "                                            \"Spread\", \"Avg MP\", \"Avg DK Points\"], \n",
    "                 y_vars='Points', size=3, aspect=0.7, plot_kws={'line_kws':{'linewidth':10,'color':'red'}})\n",
    "    g.fig.suptitle(df_names[i])\n",
    "    \n",
    "    i=i+1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### DvP Correlation with Points at Each Postion\n",
    "Uses seaborn regplot() to graph the best fit line between the mean player performances at every opponent DvP for each position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sns.set()\n",
    "i=0\n",
    "fig, ax = plt.subplots(1, 5, sharey='row', figsize=(15,5))\n",
    "plt.tight_layout()\n",
    "for df in df_list:\n",
    "    sns.set()\n",
    "    sns.regplot('L5 Dvp', 'Points', data=df, fit_reg=True, x_estimator=np.mean, truncate=True,\n",
    "                line_kws={'linewidth':10,'color':'red'}, \n",
    "                ax=ax[i]).set_title(df_names[i], fontsize = 20)    \n",
    "    i=i+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Looking at Coefficient Correlation Matrix\n",
    "Shows a table of correlation coefficients between each possible variable pair for each individual position and lastly for all positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_pg_no_points = df_pg.drop([\"Points\"],1)\n",
    "df_sg_no_points = df_sg.drop([\"Points\"],1)\n",
    "df_pf_no_points = df_pf.drop([\"Points\"],1)\n",
    "df_sf_no_points = df_sf.drop([\"Points\"],1)\n",
    "df_c_no_points = df_c.drop([\"Points\"],1)\n",
    "df_no_points = df.drop([\"Points\"],1)\n",
    "\n",
    "pg_corr_matrix = df_pg_no_points.corr()\n",
    "sg_corr_matrix = df_sg_no_points.corr()\n",
    "sf_corr_matrix = df_sf_no_points.corr()\n",
    "pf_corr_matrix = df_pf_no_points.corr()\n",
    "c_corr_matrix = df_c_no_points.corr()\n",
    "df_corr_matrix = df_no_points.corr()\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(2, 3, figsize=(15,10))\n",
    "plt.rcParams.update({'font.size': 18})\n",
    "\n",
    "smg.plot_corr(pg_corr_matrix, xnames=df_pg_no_points.columns, ax=ax[0][0], \n",
    "              title=\"Point Guards\")\n",
    "smg.plot_corr(sg_corr_matrix, xnames=df_sg_no_points.columns, ax=ax[0][1], \n",
    "              title=\"Shooting Guards\")\n",
    "smg.plot_corr(sf_corr_matrix, xnames=df_sf_no_points.columns, ax=ax[0][2], \n",
    "              title=\"Small Fowards\")\n",
    "smg.plot_corr(pf_corr_matrix, xnames=df_pf_no_points.columns, ax=ax[1][0], \n",
    "              title=\"Power Fowards\")\n",
    "smg.plot_corr(c_corr_matrix, xnames=df_c_no_points.columns, ax=ax[1][1], \n",
    "              title=\"Center\")\n",
    "smg.plot_corr(df_corr_matrix, xnames=df_no_points.columns, ax=ax[1][2], \n",
    "              title=\"All Postions\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Seperate Into Train and Test Sets\n",
    "Creates train and test sets for each position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pg_training_data = np.array(df_pg.drop(['Points'],1))[:-test_num]\n",
    "pg_training_answers = np.array(df_pg['Points'])[:-test_num]\n",
    "pg_test_data = np.array(df_pg.drop(['Points'],1))[-test_num:]\n",
    "pg_test_answers = np.array(df_pg['Points'])[-test_num:]\n",
    "\n",
    "sg_training_data = np.array(df_sg.drop(['Points'],1))[:-test_num]\n",
    "sg_training_answers = np.array(df_sg['Points'])[:-test_num]\n",
    "sg_test_data = np.array(df_sg.drop(['Points'],1))[-test_num:]\n",
    "sg_test_answers = np.array(df_sg['Points'])[-test_num:]\n",
    "\n",
    "pf_training_data = np.array(df_pf.drop(['Points'],1))[:-test_num]\n",
    "pf_training_answers = np.array(df_pf['Points'])[:-test_num]\n",
    "pf_test_data = np.array(df_pf.drop(['Points'],1))[-test_num:]\n",
    "pf_test_answers = np.array(df_pf['Points'])[-test_num:]\n",
    "\n",
    "sf_training_data = np.array(df_sf.drop(['Points'],1))[:-test_num]\n",
    "sf_training_answers = np.array(df_sf['Points'])[:-test_num]\n",
    "sf_test_data = np.array(df_sf.drop(['Points'],1))[-test_num:]\n",
    "sf_test_answers = np.array(df_sf['Points'])[-test_num:]\n",
    "\n",
    "c_training_data = np.array(df_pg.drop(['Points'],1))[:-test_num]\n",
    "c_training_answers = np.array(df_pg['Points'])[:-test_num]\n",
    "c_test_data = np.array(df_pg.drop(['Points'],1))[-test_num:]\n",
    "c_test_answers = np.array(df_pg['Points'])[-test_num:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression Vs Random Forest Vs Expert Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pg_lin_pred, pg_for_pred = ml_functions.model_analysis(pg_training_data, pg_training_answers, pg_test_data, pg_test_answers, pg_proj_points, \"PG\")\n",
    "sg_lin_pred, sg_for_pred = ml_functions.model_analysis(sg_training_data, sg_training_answers, sg_test_data, sg_test_answers, sg_proj_points, \"SG\")\n",
    "sf_lin_pred, sf_for_pred = ml_functions.model_analysis(sf_training_data, sf_training_answers, sf_test_data, sf_test_answers, sf_proj_points, \"SF\")\n",
    "pf_lin_pred, pf_for_pred = ml_functions.model_analysis(pf_training_data, pf_training_answers, pf_test_data, pf_test_answers, pf_proj_points, \"PF\")\n",
    "c_lin_pred, c_for_pred = ml_functions.model_analysis(c_training_data, c_training_answers, c_test_data, c_test_answers, c_proj_points, \"C\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine Postion Specific DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame()\n",
    "\n",
    "results['Name']= np.concatenate([pg_names_array,sg_names_array,sf_names_array,pf_names_array,c_names_array])\n",
    "results['Position']= np.concatenate([np.full(len(pg_lin_pred), \"PG\"), np.full(len(sg_lin_pred), \"SG\"),\n",
    "                                    np.full(len(sf_lin_pred), \"SF\"), np.full(len(pf_lin_pred), \"PF\"),\n",
    "                                    np.full(len(c_lin_pred), \"C\")])\n",
    "results['Salary']= np.concatenate([pg_salary, sg_salary, sf_salary, pf_salary,c_salary])\n",
    "results['Projected Points']= np.concatenate([pg_proj_points, sg_proj_points, sf_proj_points,\n",
    "                                             pf_proj_points, c_proj_points])\n",
    "results['Predicted Points']= np.concatenate([pg_lin_pred, sg_lin_pred, sf_lin_pred,\n",
    "                                             pf_lin_pred, c_lin_pred])\n",
    "results['Day']= np.concatenate([pg_date, sg_date, sf_date, pf_date,c_date])\n",
    "results['Points']= np.concatenate([pg_test_answers, sg_test_answers, sf_test_answers,\n",
    "                                             pf_test_answers, c_test_answers])\n",
    "\n",
    "print('Prediction:',metrics.mean_absolute_error(results[\"Predicted Points\"], results['Points']),',',\n",
    "      'Projected:',metrics.mean_absolute_error(results[\"Projected Points\"], results[\"Points\"]))\n",
    "\n",
    "results.to_csv('Predictions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
